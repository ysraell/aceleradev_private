{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento B:\n",
    "\n",
    "Goals:\n",
    "\n",
    "1) Extender a classe de algum dos algoritmos no formato necessário para recomendações *user-user*.\n",
    "\n",
    "2) Implementar o GridsSearch e validar seu uso para o nosso caso.\n",
    "\n",
    "3) Adaptar uma varredura para diferentes quantidades de colunas acima do método do item 2.\n",
    "\n",
    "O modelo receberá como entrar apenas o `id` da empresa e retornar uma lista do `N` mais recomendados (vizinhos mais próximos).\n",
    "\n",
    "Verifiar: o modela terá entrada de empresas novas? Acho que não.\n",
    "\n",
    "- Author: Israel Oliveira [\\[e-mail\\]](mailto:'Israel%20Oliveira%20'<prof.israel@gmail.com>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import SVD, accuracy, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-19T23:11:30+00:00\n",
      "\n",
      "CPython 3.7.7\n",
      "IPython 7.15.0\n",
      "\n",
      "compiler   : GCC 8.3.0\n",
      "system     : Linux\n",
      "release    : 4.19.76-linuxkit\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "numpy  1.18.5\n",
      "pandas 1.0.4\n",
      "\n",
      "Git hash: b4348e2f24cd733e3f1939d40228356aa358edf2\n",
      "Git repo: https://github.com/ysraell/aceleradev_private.git\n",
      "Git branch: master\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before close.\n",
    "%watermark\n",
    "%watermark --iversion\n",
    "%watermark -b -r -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega e processa o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/'\n",
    "top_cols = pd.read_csv('top_cols.csv')['cols'].to_list()\n",
    "df_marked = pd.read_csv(path_data+'estaticos_market.csv', usecols=top_cols)\n",
    "col_user = 'id'\n",
    "top_cols.remove(col_user)\n",
    "\n",
    "rest_cols = []\n",
    "for col in top_cols:\n",
    "    df_marked[col] = df_marked[col].fillna(0)*1\n",
    "\n",
    "def normalize(x):\n",
    "    return (x-np.min(x))/(np.max(x) - np.min(x)) if (np.max(x) - np.min(x)) > 0 else (x-np.min(x))\n",
    "\n",
    "escala = 100\n",
    "for col in top_cols:\n",
    "    df_marked[col] = (escala*normalize(df_marked[col].tolist())).astype(np.uint8)\n",
    "    \n",
    "remove_cols = []\n",
    "for col in top_cols:\n",
    "    if df_marked[col].nunique() == 1:\n",
    "        remove_cols.append(col)\n",
    "\n",
    "df_marked = df_marked.drop(columns=remove_cols)\n",
    "for col in remove_cols:\n",
    "    top_cols.remove(col)\n",
    "\n",
    "df_marked = pd.melt(df_marked, id_vars=[\"id\"], var_name=\"itemID\", value_name=\"rating\").rename(columns={\"id\": \"userID\"})\n",
    "\n",
    "reader = Reader(rating_scale=(0, escala))\n",
    "data = Dataset.load_from_df(df_marked[['userID', 'itemID', 'rating']], reader)\n",
    "del df_marked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 18.2032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.203169808345063"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 462298)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.trainset.all_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0293ec906c1746e1d0876f22c650bb8022f96c428300214dc973aa7a044bd30c'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.trainset.to_raw_uid(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33012803, -0.87753922, -0.16000786,  0.33690633, -0.44181853,\n",
       "        0.31283246, -0.40416128,  0.673524  , -0.74984166,  0.12221613,\n",
       "       -0.7911641 ,  0.14049286, -0.37121182,  0.89099278, -0.36245022,\n",
       "       -0.29306878,  0.29103981,  0.525298  , -0.45211667,  0.22572351,\n",
       "        0.17184372,  0.58922408,  0.41421369,  0.28501298, -0.19561715,\n",
       "       -0.27319747, -1.44398452, -0.84475615, -1.23579915, -0.10919373,\n",
       "       -0.52979   , -0.12286462, -1.41653664, -0.61992774,  0.28968281,\n",
       "        0.67964255, -0.52213828,  0.25314298,  0.31413346, -0.42081662,\n",
       "       -0.68342602,  0.43810118, -0.32876472,  0.86476891, -0.41420993,\n",
       "       -0.46208325, -0.6581106 , -0.07915893,  0.23415733,  0.86767033,\n",
       "       -0.14446805, -0.28450242,  0.99261077, -0.98603909,  0.64242801,\n",
       "        0.17820183,  0.02043893,  0.36393089,  0.03456342,  0.28366136,\n",
       "       -0.70158252,  0.54591876,  0.27118546,  0.15735987,  0.23547393,\n",
       "        0.10194708,  0.8354555 ,  0.61943589,  0.88713212, -0.01076865,\n",
       "       -0.17442195,  0.39465754, -0.43725281, -0.17609692, -0.19931346,\n",
       "       -0.14919808, -0.38950179,  0.68940607, -0.2610617 , -0.03716314,\n",
       "       -0.29010597, -0.01958671, -0.74758266,  0.12187338,  0.30518365,\n",
       "       -0.33906984, -0.01200472, -0.63456301, -0.29241625, -0.08293448,\n",
       "        0.84661683,  0.54070352, -0.36557068, -0.64164908, -0.71881485,\n",
       "       -0.54263432,  0.17526941, -0.47882432,  1.02618892, -0.03262277])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.pu[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
