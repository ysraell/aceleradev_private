{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment D2 \n",
    "- Uma quebra no D para reimplemtação do SVD sem o módulo Surprise\n",
    "\n",
    "Ideas:\n",
    "\n",
    "1) Reimplementar o SVD.\n",
    "\n",
    "2) Implementar um framework de busca de hiperparâmetros.\n",
    "\n",
    "2.1) N fatores (`n_factors`) da decomposição FM.\n",
    "\n",
    "2.2) N top colunas (`top_cols`) do dataset.\n",
    "\n",
    "2.3) Parâmetro $L$ (`recomender(...,L,...)`).\n",
    "\n",
    "\n",
    "- Author: Israel Oliveira [\\[e-mail\\]](mailto:'Israel%20Oliveira%20'<prof.israel@gmail.com>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType, List\n",
    "import functools\n",
    "import operator\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pythran\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "import jax.numpy as npj\n",
    "from jax import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-27T20:11:32+00:00\n",
      "\n",
      "CPython 3.7.7\n",
      "IPython 7.15.0\n",
      "\n",
      "compiler   : GCC 8.3.0\n",
      "system     : Linux\n",
      "release    : 4.19.76-linuxkit\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "loguru 0.5.1\n",
      "pythran 0.9.5\n",
      "pythran 0.9.5\n",
      "jax 0.1.71\n",
      "scipy 1.4.1\n",
      "pythran 0.9.5\n",
      "pandas  1.0.5\n",
      "numpy   1.19.0\n",
      "\n",
      "Git hash: 6aae247f20fe42b71b7beb759311d36150482667\n",
      "Git repo: https://github.com/ysraell/aceleradev_private.git\n",
      "Git branch: master\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before close.\n",
    "%watermark\n",
    "%watermark -p loguru\n",
    "%watermark -p pythran\n",
    "%watermark -p pythran\n",
    "%watermark -p jax\n",
    "%watermark -p scipy\n",
    "%watermark --iversion\n",
    "%watermark -b -r -g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From exp. D2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-27 20:11:35.602 | INFO     | __main__:<module>:1 - Carregando e processando o dataset...\n",
      "2020-06-27 20:11:59.894 | INFO     | __main__:<module>:43 - ...pronto!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.info(\"Carregando e processando o dataset...\")\n",
    "\n",
    "path_data = '../data/'\n",
    "top_cols = pd.read_csv('top_cols.csv')['cols'].to_list()\n",
    "df_marked = pd.read_csv(path_data+'estaticos_market.csv', usecols=top_cols)\n",
    "col_user = 'id'\n",
    "top_cols.remove(col_user)\n",
    "\n",
    "rest_cols = []\n",
    "for col in top_cols:\n",
    "    df_marked[col] = df_marked[col].fillna(0)*1\n",
    "    \n",
    "def normalize(x):\n",
    "    return (x-np.min(x))/(np.max(x) - np.min(x)) if (np.max(x) - np.min(x)) > 0 else (x-np.min(x))\n",
    "\n",
    "escala = 255\n",
    "for col in top_cols:\n",
    "    try:\n",
    "        df_marked[col] = (escala*normalize(df_marked[col].tolist())).astype(np.uint8)\n",
    "    except:\n",
    "        maping = {val:i+1 for i,val in enumerate(df_marked[col].unique())}\n",
    "        df_marked[col] = df_marked[col].apply(lambda x: maping[x])\n",
    "        df_marked[col] = (escala*normalize(df_marked[col].tolist())).astype(np.uint8)\n",
    "    \n",
    "remove_cols = []\n",
    "for col in top_cols:\n",
    "    if df_marked[col].nunique() == 1:\n",
    "        remove_cols.append(col)\n",
    "\n",
    "df_marked = df_marked.drop(columns=remove_cols)\n",
    "for col in remove_cols:\n",
    "    top_cols.remove(col)\n",
    "\n",
    "df_ep_list = [pd.read_csv(path_data+'estaticos_portfolio{}.csv'.format(i+1)) for i in range(3)]\n",
    "tmp = []\n",
    "for i in range(3):\n",
    "    df_ep_list[i]['P'] = i+1 \n",
    "    tmp.append(df_ep_list[i][['id','P']])\n",
    "df_ep = pd.concat(tmp)\n",
    "del df_ep_list\n",
    "del tmp\n",
    "\n",
    "logger.info(\"...pronto!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pythranized_b9af09ce3bb3a83c5d007fe0e852e1cd.cpython-37m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!ls *.so && rm -f *.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pythran.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pythran -fopenmp\n",
    "#pythran export normalizeitor(float64[][])\n",
    "#pythran export transformer(float64[][])\n",
    "#pythran export vector_distance_pythran(int8[][],int8[])\n",
    "#pythran export pairwise_distance_pythran(int8[][])\n",
    "#pythran export pairs_distance_pythran(int8[][],int8[][])\n",
    "\n",
    "def normalizeitor(x):\n",
    "    return (x -x.min())/(x.max() - x.min() +1e-10)\n",
    "\n",
    "def transformer(U):\n",
    "    for i in range(len(U)):\n",
    "        U[i] = 127*normalizeitor(U[i])\n",
    "    return U\n",
    "\n",
    "def vector_distance_pythran(X,vec):\n",
    "    return abs(X - vec).sum(-1)\n",
    "\n",
    "def pairwise_distance_pythran(X):\n",
    "    i = X.shape[0]\n",
    "    j = X.shape[1]\n",
    "    return abs(X.reshape((i, 1, j)) - X).sum(-1)\n",
    "\n",
    "def pairs_distance_pythran(X,Y):\n",
    "    i = X.shape[0]\n",
    "    j = X.shape[1]\n",
    "    return abs(X.reshape((i, 1, j)) - Y).sum(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pythranized_b9af09ce3bb3a83c5d007fe0e852e1cd.cpython-37m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!ls *.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat(a):\n",
    "    return functools.reduce(operator.iconcat, a, []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df_marked[df_marked.columns[1:]].values.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462298, 86)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_svd(M):\n",
    "    u, _, _ = np.linalg.svd(M, full_matrices=False)\n",
    "    return u\n",
    "\n",
    "def sp_svds(M,k=10):\n",
    "    A = csc_matrix(M, dtype=float)\n",
    "    u, _, _ = svds(A, k=k)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sp_svds(M,k=85)\n",
    "%timeit np_svd(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_svd_j(M):\n",
    "    u, _, _ = npj.linalg.svd(M, full_matrices=False)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_svd_jit = jit(np_svd_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_list = []\n",
    "for _ in range(100):\n",
    "    ts = [0, 0]\n",
    "    np.random.shuffle(M)\n",
    "    t = time()\n",
    "    u = np_svd(M)\n",
    "    ts[0] = time()-t\n",
    "    t = time()\n",
    "    u = np_svd_jit(M)\n",
    "    ts[1] = time()-t\n",
    "    times_list.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(times_list, columns=['NP','NP/JAX/JIT']).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_distance(X,vec):\n",
    "    return abs(X - vec).sum(-1)\n",
    "\n",
    "def pairwise_distance(X):\n",
    "    return abs(X[:, None, :] - X).sum(-1)\n",
    "\n",
    "def pairs_distance(X,Y):\n",
    "    return abs(X[:, None, :] - Y).sum(-1)\n",
    "\n",
    "def vector_distance_float(X,vec):\n",
    "    return abs((X - vec).astype(npj.float32)).sum(-1)\n",
    "\n",
    "def pairwise_distance_float(X):\n",
    "    return abs((X[:, None, :] - X).astype(npj.float32)).sum(-1)\n",
    "\n",
    "def pairs_distance_float(X,Y):\n",
    "    return abs((X[:, None, :] - Y).astype(npj.float32)).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_distance_jit = jit(vector_distance_float)\n",
    "pairwise_distance_jit = jit(pairwise_distance_float)\n",
    "pairs_distance_jit = jit(pairs_distance_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2     \r"
     ]
    }
   ],
   "source": [
    "times_list = []\n",
    "N = 2\n",
    "for i in range(N):\n",
    "    print(\"{}/{}     \".format(i+1,N), end='\\r')\n",
    "    ts = [0, 0, 0]\n",
    "    np.random.shuffle(M)\n",
    "    M = deepcopy(transformer(M.astype(np.float64)).astype(np.int8))\n",
    "    vec = deepcopy(M[:100])\n",
    "    t = time()\n",
    "    _ = pairs_distance(vec,M)\n",
    "    ts[0] = time()-t\n",
    "    t = time()\n",
    "    _ = pairs_distance_pythran(vec,M)\n",
    "    ts[1] = time()-t\n",
    "    A = M.astype(npj.float32)\n",
    "    t = time()\n",
    "    _ = pairs_distance_jit(vec,M)\n",
    "    ts[2] = time()-t\n",
    "    times_list.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(times_list, columns=['Pure','Pythran','JAX/JIT']).describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.056382*460000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Uid = NewType('uid', int)\n",
    "Raw = NewType('raw', str)\n",
    "\n",
    "class ExSVD():\n",
    "    \"\"\"\n",
    "        Classe para SVD.\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,stateless: bool = False):\n",
    "        self.matrix_dict = {}\n",
    "        self.matrix_dict_2 = {}\n",
    "        self.stateless = stateless\n",
    "\n",
    "    def fit(self,trainset = None):\n",
    "        \"\"\"\n",
    "            Reimplementei a SVD.fit para colocar um logger nível INFO.\n",
    "        \"\"\"\n",
    "        #logger.info(\"Treinando modelo SVD...\")\n",
    "        #logger.info(\"Pronto!\")\n",
    "    \n",
    "    def _get_neighbors(self,uid: Uid, k: int = 1, black_list: List[Uid] = []) -> List[Uid]:\n",
    "        \"\"\"\n",
    "            Calcula todas as distâncias entre 'uid' de entrada e todos os outros 'uid'.\n",
    "            A distância calciulada é armazenda e não calculada novamente. \n",
    "        \"\"\"\n",
    "        black_list.append(uid)\n",
    "        k = k if k >= 0 else 0\n",
    "        #logger.info(\"Calculando todos os vizinhos...\")\n",
    "        #for uid2 in tqdm(self.trainset.all_users()):\n",
    "        for uid2 in self.trainset.all_users():\n",
    "            ordered = tuple(sorted((uid,uid2)))\n",
    "            if (uid2 not in black_list) and (ordered not in self.matrix_dict.keys()):\n",
    "                self.matrix_dict[ordered] = cosine(self.pu[uid],self.pu[uid2])\n",
    "        out = [x[0] for x in sorted(\n",
    "            [\n",
    "                (uid2, self.matrix_dict[tuple(sorted((uid,uid2)))]) \n",
    "                for uid2 in self.trainset.all_users()\n",
    "                if (uid2 not in black_list)\n",
    "            ], key=lambda x: x[1])][:k-1]\n",
    "        if self.stateless:\n",
    "            del self.matrix_dict\n",
    "            self.matrix_dict = {}\n",
    "        return out\n",
    "\n",
    "    def _get_neighbors_2(self,uid: Uid, k: int = 1, black_list: List[Uid] = []) -> List[Uid]:\n",
    "        \"\"\"\n",
    "            Calcula todas as distâncias entre 'uid' de entrada e todos os outros 'uid'.\n",
    "            A distância calciulada é armazenda e não calculada novamente. \n",
    "        \"\"\"\n",
    "        black_list.append(uid)\n",
    "        k = k if k >= 0 else 0\n",
    "        #logger.info(\"Calculando todos os vizinhos...\")\n",
    "        #for uid2 in tqdm(self.trainset.all_users()):\n",
    "        if uid not in self.matrix_dict_2.keys():\n",
    "            Un = transformer(self.pu).astype(np.int8)\n",
    "            self.matrix_dict_2[uid] = vector_distance_pythran(Un,Un[uid])\n",
    "        out = [x[0] for x in sorted(\n",
    "            [\n",
    "                (uid2, self.matrix_dict_2[uid][uid2])\n",
    "                for uid2 in self.trainset.all_users()\n",
    "                if (uid2 not in black_list)\n",
    "            ], key=lambda x: x[1])][:k-1]\n",
    "        if self.stateless:\n",
    "            del self.matrix_dict\n",
    "            self.matrix_dict = {}\n",
    "        return out\n",
    "    \n",
    "    def _uid2raw(self, uid: Uid)-> str:\n",
    "        '''\n",
    "            uid -> raw.\n",
    "            Valor interno para externo, o nome original do usuário.\n",
    "        '''\n",
    "        return self.trainset.to_raw_uid(uid)\n",
    "    \n",
    "    def _raw2uid(self, raw: Raw)-> int:\n",
    "        '''\n",
    "            raw -> uid.\n",
    "            Valor externo para interno, o id interno do usuários..\n",
    "        '''\n",
    "        return self.trainset.to_inner_uid(raw)\n",
    "    \n",
    "    def recomender(self, in_list: List[Raw], k: int = 1, L: int = 3, Fk: int = 1, limit: int = 100)-> List[Raw]:\n",
    "        '''\n",
    "            Faz as recomendacoes.\n",
    "            ##### Função incompleta #####\n",
    "        '''\n",
    "        # Pega quantas recomendações por usuário em `in_list`,\n",
    "        # mas sem deixar faltar\n",
    "        N_in = len(in_list)\n",
    "        k = k if k > 0 else 1\n",
    "        R_per_in = L*(k//N_in + min(k%N_in,1))\n",
    "\n",
    "        # Pega os `uid`\n",
    "        uid_in_list = []\n",
    "        for raw in in_list:\n",
    "            uid_in_list.append(self._raw2uid(raw))\n",
    "\n",
    "        # Pega os vizinhos mais próximos de cada uid de entrada.\n",
    "        done = False\n",
    "        flag = True\n",
    "        Rounds = 0\n",
    "        while limit and (not done):\n",
    "            Rounds += 1\n",
    "            # Ele sempre pega todos novamente.\n",
    "            recomendations_list = []\n",
    "            for i,uid in enumerate(uid_in_list):\n",
    "                #logger.info(\"Calculando todos os vizinhos...{:,}/{:,} (Round: {:,}).\".format(i+1,N_in,Rounds))\n",
    "                #recomendations_list.append(self._get_neighbors(uid,R_per_in,in_list))\n",
    "                recomendations_list.append(self._get_neighbors_2(uid,R_per_in,in_list))\n",
    "            # Quando limit = 0, encerra.\n",
    "            limit -= 1\n",
    "            # Quando tem gente o suficiente, encerra.\n",
    "            if len(set(flat(recomendations_list))) >= Fk*k:\n",
    "                done = True\n",
    "            # Depois do primeiro loop, pega um a mais.\n",
    "            R_per_in += 1\n",
    "\n",
    "        # Aqui gera um dicionário ordenando por votacao.\n",
    "        count_rec = Counter(flat(recomendations_list)) # A votação!!\n",
    "        count_rec = list(count_rec.items())\n",
    "        ct_pos = defaultdict(list)\n",
    "        #ct_pos_inv = defaultdict(list)\n",
    "        while count_rec:\n",
    "            tmp = count_rec.pop(0)\n",
    "            ct_pos[tmp[1]].append(tmp[0])\n",
    "            #ct_pos_inv[tmp[0]].append(tmp[1])\n",
    "\n",
    "        # Aqui considera a posiçao de vizinhos mais proximos.\n",
    "        #nn_pos = defaultdict(list)\n",
    "        nn_pos_inv = defaultdict(list)\n",
    "        tmp = deepcopy(recomendations_list)\n",
    "        while tmp:\n",
    "            tmp2 = tmp.pop(0)\n",
    "            n = 0\n",
    "            while tmp2:\n",
    "                n += 1\n",
    "                tmp3 = tmp2.pop(0)\n",
    "                #nn_pos[n].append(tmp3)\n",
    "                nn_pos_inv[tmp3].append(n)\n",
    "\n",
    "        # Vai separando por votação e ordem de proximidade como desempate.      \n",
    "        votos_list = list(ct_pos.keys())\n",
    "        out_uid = []\n",
    "        while votos_list and k:\n",
    "            votos = max(votos_list)\n",
    "            votos_list.remove(votos)\n",
    "            tmp = sorted([(tmp, min(nn_pos_inv[tmp])) for tmp in ct_pos[votos]], key=lambda x: x[1])\n",
    "            while tmp and k:\n",
    "                out_uid.append(tmp.pop(0)[0])\n",
    "                k -= 1\n",
    "\n",
    "        # converte para Raw e \"joga fora\".\n",
    "        return [self._uid2raw(uid) for uid in out_uid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_algo = ExSVD(stateless=True, n_factors=200, n_epochs=20, verbose=True)\n",
    "ex_algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo de validação simples, para cada uma empresa no portfólio pegar N recomendações e ver se uma delas está no portfólio. Se está, soma 1, se não, soma 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "tmp = []\n",
    "n = 0\n",
    "Nu = 10\n",
    "times = []\n",
    "for row in df_ep.sample(n=Nu).iterrows():\n",
    "    t = time()\n",
    "    n += 1\n",
    "    print(\"Empresa {:,}/{:,}.\".format(n,Nu), end='\\r')\n",
    "    recs = ex_algo.recomender([row[1].id],k=N)\n",
    "    tmp.append(any([x in df_ep.loc[df_ep.P == row[1].P].id.to_list() for x in recs])*1)\n",
    "    times.append(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(times, columns=['time']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Item 2 pronto**, usei o Pythran e ficou bem mais rápido, mas o passo de treino não está.\n",
    "Creio que é chegado o momento de jogar fora o Surprise antes de implementar a busca por hiperparâmetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
