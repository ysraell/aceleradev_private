{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment F\n",
    "\n",
    "2) Implementar um framework de busca de hiperparâmetros.\n",
    "\n",
    "2.1) Parâmetros específicos para cada método de processamento do ds.\n",
    "\n",
    "2.2) N top colunas (`top_cols`) do dataset.\n",
    "\n",
    "2.3) Parâmetro $L$ (`recomender(...,L,...)`).\n",
    "\n",
    "5) Implementar como entrada uma empresa nova, conter mapeamento de valores.\n",
    "\n",
    "Talvez criar o notebook da Second_View, com:\n",
    "1) Verificar `sklearn.inspection.permutation_importance`.\n",
    "\n",
    "- Author: Israel Oliveira [\\[e-mail\\]](mailto:'Israel%20Oliveira%20'<prof.israel@gmail.com>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType, List\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import FactorAnalysis, FastICA, PCA, IncrementalPCA, NMF, TruncatedSVD\n",
    "from collections import defaultdict, Counter\n",
    "import functools\n",
    "import operator\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  1.19.0\n",
      "pandas 1.0.5\n",
      "2020-07-30 \n",
      "\n",
      "CPython 3.7.8\n",
      "IPython 7.16.1\n",
      "\n",
      "compiler   : GCC 8.3.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-7634-generic\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 9ee5ae65e071e8358b42d2bf1d55d9f66602521c\n",
      "Git repo   : https://github.com/ysraell/aceleradev_private.git\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before close.\n",
    "%watermark -d --iversion -b -r -g -m -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Manhattan(X,vec):\n",
    "    return abs(X - vec).sum(-1)\n",
    "\n",
    "def Camberra(X,vec):\n",
    "    return abs((X - vec)/(X + vec)).sum(-1)\n",
    "\n",
    "def BrayCurtis(X,vec):\n",
    "    return abs((X - vec)).sum(-1) / abs((X - vec)).sum(-1).sum(-1)\n",
    "\n",
    "def np_cossine(X,vec):\n",
    "    return np.array([sum(X[i]*vec) / sum(X[i]**2)*sum(vec**2) for i in range(X.shape[0])])\n",
    "\n",
    "def npj_cossine(X,vec):\n",
    "    return npj.array([sum(X[i]*vec) / sum(X[i]**2)*sum(vec**2) for i in range(X.shape[0])])\n",
    "\n",
    "def scy_cossine(X,vec):\n",
    "    return np.array([cosine(X[i],vec) for i in range(X.shape[0])])\n",
    "\n",
    "dist_func = [Manhattan, Camberra, BrayCurtis, np_cossine, scy_cossine]\n",
    "\n",
    "def Nothing(arg):\n",
    "    return arg\n",
    "\n",
    "def npSVD(M):\n",
    "    u, _, _ = np.linalg.svd(M, full_matrices=False)\n",
    "    return u\n",
    "\n",
    "def _PCA(M,n_components=None):\n",
    "    out = PCA(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _FastICA(M,n_components=None):\n",
    "    out = FastICA(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _FactorAnalysis(M,n_components=None):\n",
    "    out = FactorAnalysis(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _IncrementalPCA(M,n_components=None):\n",
    "    out = IncrementalPCA(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _TruncatedSVD(M,n_components=None):\n",
    "    out = TruncatedSVD(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _NMF(M,n_components=None):\n",
    "    out = NMF(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "redux_func = [Nothing, npSVD, _NMF, _TruncatedSVD, _IncrementalPCA, _FactorAnalysis, _FastICA, _PCA]\n",
    "\n",
    "def escalaropt_missings(df: pd.DataFrame, score: dict):\n",
    "    df_score = pd.DataFrame(score.items(), columns=['col','score'])\n",
    "    df_score['escala_opt'] = 1-normalize((np.sqrt(df_score.score)))\n",
    "    df_score['escala_opt'] = df_score['escala_opt'].apply(lambda x: max(x,0.1))\n",
    "    for _,row in df_score.iterrows():\n",
    "        df[row.col] = row.escala_opt*df[row.col]\n",
    "    return df\n",
    "\n",
    "def escalaropt_std(df: pd.DataFrame, score: dict):\n",
    "    df_score = pd.DataFrame(score.items(), columns=['col','score'])\n",
    "    df_score['escala_opt'] = normalize([np.sqrt(np.sqrt(np.sqrt(df[col].std()))) for col in df_score['col']])\n",
    "    df_score['escala_opt'] = df_score['escala_opt'].apply(lambda x: max(x,0.1))\n",
    "    for _,row in df_score.iterrows():\n",
    "        df[row.col] = row.escala_opt*df[row.col]\n",
    "    return df\n",
    "\n",
    "def escalaropt_entropy(df: pd.DataFrame, score: dict):\n",
    "    df_score = pd.DataFrame(score.items(), columns=['col','score'])\n",
    "    df_score['escala_opt'] = normalize([(-sum((df[col]+1)*np.log(df[col]+1))) for col in df_score['col']])\n",
    "    df_score['escala_opt'] = df_score['escala_opt'].apply(lambda x: max(x,0.1))\n",
    "    for _,row in df_score.iterrows():\n",
    "        df[row.col] = row.escala_opt*df[row.col]\n",
    "    return df\n",
    "\n",
    "def scalarop_nothing(arg, arg2):\n",
    "    return arg\n",
    "\n",
    "procDS_func = [scalarop_nothing, escalaropt_missings, escalaropt_std, escalaropt_entropy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage.ipynb  data  src\n"
     ]
    }
   ],
   "source": [
    "!ls ../app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../app/src/')\n",
    "from train import *\n",
    "from recommender import Recommender \n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 22:19:02.379 | INFO     | utils:load_dataset:82 - Carregando dataset de treino...\n",
      "2020-07-30 22:19:19.054 | INFO     | utils:load_dataset:91 - ...pronto!\n",
      "2020-07-30 22:19:19.055 | INFO     | utils:load_dataset:95 - Carregando dataset de teste...\n",
      "2020-07-30 22:19:19.065 | INFO     | utils:load_dataset:104 - ...pronto!\n",
      "2020-07-30 22:19:19.066 | INFO     | utils:feat_proc:128 - Processando as features...\n",
      "2020-07-30 22:20:11.255 | INFO     | utils:feat_proc:163 - ...pronto!\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = load_dataset(path_data = '../app/data/', test_list = [0, 1], train_test_merged = False)\n",
    "ds, score = feat_proc(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search(N=1, process_values = Nothing, factorize = Nothing, vector_distance_list = [Manhattan]):\n",
    "    ex_algo = ExMatrix(process_values = process_values, factorize = factorize)\n",
    "    ex_algo.fit(ds, score)\n",
    "    out = {}\n",
    "    for dist in vector_distance_list:\n",
    "        ex_algo.vector_distance = dist\n",
    "        print(dist.__name__)\n",
    "        tmp ={1: [], 2: []}\n",
    "        t = time()\n",
    "        for row in tqdm(df_test.iterrows()):\n",
    "            recs = ex_algo.recomender([row[1].id],k=N)\n",
    "            tmp[row[1].P].append(any([x in df_test.loc[df_test.P == row[1].P].id.to_list() for x in recs])*1)\n",
    "        t = time()-t\n",
    "        out[dist.__name__] = {i: (sum(val)/max(1,len(val)), sum(val), len(val)) for i,val in tmp.items()}\n",
    "        out[dist.__name__]['t'] = t\n",
    "    return out\n",
    "\n",
    "def save_results(results,df_e):\n",
    "    df = pd.DataFrame(results, columns=['pre_proc','redux_func','n_components','dist','t','P1pp','P1_True','P1_len','P2pp','P2_True','P2_len'])\n",
    "    out = pd.concat([df_e, df])\n",
    "    #df_laoded.df_laodedto_csv('Results_redux_prepro.csv',index=False)\n",
    "    return out\n",
    "\n",
    "n_components_dict = {Nothing.__name__ : False,\n",
    "                  #_npSVDj.__name__: False,\n",
    "                  npSVD.__name__: False,\n",
    "                  _NMF.__name__ : True,\n",
    "                  _TruncatedSVD.__name__ : True,\n",
    "                  _IncrementalPCA.__name__ : True,\n",
    "                  _FactorAnalysis.__name__ : True,\n",
    "                  _FastICA.__name__ : True,\n",
    "                  _PCA.__name__ : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = [Manhattan] #[Manhattan, scy_cossine, Camberra, BrayCurtis, np_cossine] #[Manhattan, Camberra, BrayCurtis] #dist_func\n",
    "proc_list = procDS_func #procDS_func #[Nothing] #procDS_func\n",
    "redux_list = [_NMF] #redux_func #[Nothing] #[Nothing, npSVD, _NMF, _PCA, _FactorAnalysis] #redux_func\n",
    "n_components_list = [n for n in range(30,90,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['scalarop_nothing', '_NMF', 30].\n",
      "Done: ['scalarop_nothing', '_NMF', 30].\n",
      "Done?: ['scalarop_nothing', '_NMF', 35].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 22:20:12.893 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-30 22:20:13.023 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-30 22:25:09.205 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [11:48,  1.17it/s]\n",
      "2020-07-30 22:36:57.735 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-30 22:36:57.850 | INFO     | model:fit:73 - Fatorizando.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['scalarop_nothing', '_NMF', 40].\n",
      "Done: ['scalarop_nothing', '_NMF', 40].\n",
      "Done?: ['scalarop_nothing', '_NMF', 45].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-30 22:43:15.641 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:19,  1.12it/s]\n",
      "2020-07-30 22:55:35.071 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-30 22:55:35.187 | INFO     | model:fit:73 - Fatorizando.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['scalarop_nothing', '_NMF', 50].\n",
      "Done: ['scalarop_nothing', '_NMF', 50].\n",
      "Done?: ['scalarop_nothing', '_NMF', 55].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-30 23:04:39.909 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:59,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['scalarop_nothing', '_NMF', 60].\n",
      "Done: ['scalarop_nothing', '_NMF', 60].\n",
      "Done?: ['scalarop_nothing', '_NMF', 65].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 23:17:39.600 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-30 23:17:39.848 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-30 23:29:16.499 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [13:19,  1.04it/s]\n",
      "2020-07-30 23:42:36.044 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-30 23:42:36.159 | INFO     | model:fit:73 - Fatorizando.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['scalarop_nothing', '_NMF', 70].\n",
      "Done: ['scalarop_nothing', '_NMF', 70].\n",
      "Done?: ['scalarop_nothing', '_NMF', 75].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-30 23:57:05.172 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [13:15,  1.04it/s]\n",
      "2020-07-31 00:10:21.376 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-31 00:10:21.490 | INFO     | model:fit:73 - Fatorizando.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['scalarop_nothing', '_NMF', 80].\n",
      "Done: ['scalarop_nothing', '_NMF', 80].\n",
      "Done?: ['scalarop_nothing', '_NMF', 85].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 00:28:20.979 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [14:01,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_missings', '_NMF', 30].\n",
      "Done: ['escalaropt_missings', '_NMF', 30].\n",
      "Done?: ['escalaropt_missings', '_NMF', 35].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 00:42:22.314 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-31 00:42:22.727 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 00:47:44.028 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [11:42,  1.18it/s]\n",
      "2020-07-31 00:59:27.076 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_missings', '_NMF', 40].\n",
      "Done: ['escalaropt_missings', '_NMF', 40].\n",
      "Done?: ['escalaropt_missings', '_NMF', 45].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 00:59:27.481 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 01:06:37.428 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:22,  1.12it/s]\n",
      "2020-07-31 01:19:00.469 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_missings', '_NMF', 50].\n",
      "Done: ['escalaropt_missings', '_NMF', 50].\n",
      "Done?: ['escalaropt_missings', '_NMF', 55].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 01:19:00.869 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 01:27:24.238 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:40,  1.09it/s]\n",
      "2020-07-31 01:40:04.487 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_missings', '_NMF', 60].\n",
      "Done: ['escalaropt_missings', '_NMF', 60].\n",
      "Done?: ['escalaropt_missings', '_NMF', 65].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 01:40:04.918 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 01:52:11.104 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [13:07,  1.05it/s]\n",
      "2020-07-31 02:05:19.136 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_missings', '_NMF', 70].\n",
      "Done: ['escalaropt_missings', '_NMF', 70].\n",
      "Done?: ['escalaropt_missings', '_NMF', 75].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 02:05:19.544 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 02:20:08.258 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [13:51,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_missings', '_NMF', 80].\n",
      "Done: ['escalaropt_missings', '_NMF', 80].\n",
      "Done?: ['escalaropt_missings', '_NMF', 85].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 02:33:59.861 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-31 02:34:00.343 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 02:51:50.324 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [13:37,  1.02it/s]\n",
      "2020-07-31 03:05:27.703 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_std', '_NMF', 30].\n",
      "Done: ['escalaropt_std', '_NMF', 30].\n",
      "Done?: ['escalaropt_std', '_NMF', 35].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 03:05:28.752 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 03:10:08.231 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [11:58,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_std', '_NMF', 40].\n",
      "Done: ['escalaropt_std', '_NMF', 40].\n",
      "Done?: ['escalaropt_std', '_NMF', 45].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 03:22:06.901 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-31 03:22:07.968 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 03:28:26.593 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:25,  1.12it/s]\n",
      "2020-07-31 03:40:52.106 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_std', '_NMF', 50].\n",
      "Done: ['escalaropt_std', '_NMF', 50].\n",
      "Done?: ['escalaropt_std', '_NMF', 55].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 03:40:53.171 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 03:50:07.086 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [13:08,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_std', '_NMF', 60].\n",
      "Done: ['escalaropt_std', '_NMF', 60].\n",
      "Done?: ['escalaropt_std', '_NMF', 65].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 04:03:15.516 | INFO     | model:fit:69 - Processando valores.\n",
      "2020-07-31 04:03:16.596 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 04:14:51.235 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:05,  1.14it/s]\n",
      "2020-07-31 04:26:57.321 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_std', '_NMF', 70].\n",
      "Done: ['escalaropt_std', '_NMF', 70].\n",
      "Done?: ['escalaropt_std', '_NMF', 75].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 04:26:58.277 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 04:40:02.130 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:22,  1.12it/s]\n",
      "2020-07-31 04:52:24.517 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_std', '_NMF', 80].\n",
      "Done: ['escalaropt_std', '_NMF', 80].\n",
      "Done?: ['escalaropt_std', '_NMF', 85].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 04:52:25.478 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 05:08:31.713 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:48,  1.08it/s]\n",
      "2020-07-31 05:21:20.106 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_entropy', '_NMF', 30].\n",
      "Done: ['escalaropt_entropy', '_NMF', 30].\n",
      "Done?: ['escalaropt_entropy', '_NMF', 35].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 05:21:27.092 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 05:25:39.521 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [10:57,  1.26it/s]\n",
      "2020-07-31 05:36:37.709 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_entropy', '_NMF', 40].\n",
      "Done: ['escalaropt_entropy', '_NMF', 40].\n",
      "Done?: ['escalaropt_entropy', '_NMF', 45].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 05:36:44.702 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 05:42:23.300 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [11:18,  1.22it/s]\n",
      "2020-07-31 05:53:42.349 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_entropy', '_NMF', 50].\n",
      "Done: ['escalaropt_entropy', '_NMF', 50].\n",
      "Done?: ['escalaropt_entropy', '_NMF', 55].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 05:53:49.344 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 06:01:24.855 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [11:37,  1.19it/s]\n",
      "2020-07-31 06:13:02.120 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_entropy', '_NMF', 60].\n",
      "Done: ['escalaropt_entropy', '_NMF', 60].\n",
      "Done?: ['escalaropt_entropy', '_NMF', 65].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 06:13:09.105 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 06:23:39.889 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [11:56,  1.16it/s]\n",
      "2020-07-31 06:35:36.719 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_entropy', '_NMF', 70].\n",
      "Done: ['escalaropt_entropy', '_NMF', 70].\n",
      "Done?: ['escalaropt_entropy', '_NMF', 75].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 06:35:43.712 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 06:48:44.959 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:16,  1.13it/s]\n",
      "2020-07-31 07:01:01.824 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_entropy', '_NMF', 80].\n",
      "Done: ['escalaropt_entropy', '_NMF', 80].\n",
      "Done?: ['escalaropt_entropy', '_NMF', 85].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 07:01:08.806 | INFO     | model:fit:73 - Fatorizando.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "2020-07-31 07:17:04.306 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [12:36,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "results_csv_name = 'Results_A1.csv'\n",
    "df_laoded = pd.read_csv(results_csv_name)\n",
    "\n",
    "n=0\n",
    "for redux in redux_list:\n",
    "    for proc in proc_list:\n",
    "        if n_components_dict[redux.__name__]:\n",
    "            for n_components in n_components_list:\n",
    "                cond = (df_laoded['pre_proc'] == proc.__name__) & (df_laoded['redux_func'] == redux.__name__) & (df_laoded['n_components'] == n_components)\n",
    "                print(\"Done?: {}.\".format([proc.__name__, redux.__name__, n_components]))\n",
    "                if (sum(cond) == 0) or (not all([d.__name__ in df_laoded.dist.loc[cond].unique() for d in dist_list])):\n",
    "                    dist_list_tmp = [d for d in dist_list if d.__name__ not in df_laoded.dist.loc[cond].unique()]\n",
    "                    def redux_tmp(M):\n",
    "                        return redux(M,n_components=n_components)\n",
    "                    tmp = Search(process_values = proc, factorize = redux_tmp, vector_distance_list = dist_list_tmp)\n",
    "                    results = [[proc.__name__, redux.__name__, n_components] + r for r in [[key]+[tmp[key]['t']]+flat([list(tmp[key][i+1]) for i in range(2)]) for key in tmp.keys()]]\n",
    "                    df_laoded = save_results(results,df_laoded)\n",
    "                    df_laoded.to_csv(results_csv_name,index=False)\n",
    "                else:\n",
    "                    print(\"Done: {}.\".format([proc.__name__, redux.__name__, n_components]))\n",
    "        else:\n",
    "            n_components = ds.shape[1]\n",
    "            cond = (df_laoded['pre_proc'] == proc.__name__) & (df_laoded['redux_func'] == redux.__name__) & (df_laoded['n_components'] == n_components)\n",
    "            print(\"Done?: {}.\".format([proc.__name__, redux.__name__, n_components]))\n",
    "            if (sum(cond) == 0) or (not all([d.__name__ in df_laoded.dist.loc[cond].unique() for d in dist_list])):\n",
    "                dist_list_tmp = [d for d in dist_list if d.__name__ not in df_laoded.dist.loc[cond].unique()]\n",
    "                tmp = Search(process_values = proc, factorize = redux, vector_distance_list= dist_list_tmp)\n",
    "                results = [[proc.__name__, redux.__name__, n_components] + r for r in [[key]+[tmp[key]['t']]+flat([list(tmp[key][i+1]) for i in range(2)]) for key in tmp.keys()]]\n",
    "                df_laoded = save_results(results,df_laoded)\n",
    "                df_laoded.to_csv(results_csv_name,index=False)\n",
    "            else:\n",
    "                print(\"Done: {}.\".format([proc.__name__, redux.__name__, n_components]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(columns=['pre_proc','redux_func','n_components','dist','t','P1pp','P1_True','P1_len','P2pp','P2_True','P2_len'])\n",
    "#df.to_csv(results_csv_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
