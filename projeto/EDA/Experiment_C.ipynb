{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment C \n",
    "\n",
    "Ideas:\n",
    "\n",
    "~~1) Estudar as diferentes distâncias para vetores 1-D em `scipy.spatial.distance`.~~\n",
    "\n",
    "~~2) De 1, implementar e otimizar os que melhor performam comos portfólios.~~\n",
    "\n",
    "3) Ver a possibilidade de recomendar com base em 2 ou mais empresas (`users`)\n",
    "\n",
    "Eu não queria usar valores médios entre os vetores ou representantes de clusters,\n",
    "pois creio que a distorção espacial ao calcular um vetor médio pode ser maior quanto\n",
    "mais empresas eu tiver de entrada. Penso que uma abordagem interessante é que garante\n",
    "pelo menos uma proximidade maior entre as empresas é por votação. Via clsuter e vetor\n",
    "médio eu faço recomendações que não são as mais próximas de todos, mas nem tão distantes,\n",
    "mas isso pode excluir os potenciais melhores recomendações. Com votação, eu aumento as \n",
    "chances de recomendar empresas que são muito próximas para umas, ainda que seja distante\n",
    "de outras. \n",
    "\n",
    "4) Validar as recomendações com os portfólios.\n",
    "\n",
    "Como utilizar os portfólios dados para validar o modelo? Não sabe-se a ordem em que os\n",
    "portfólios foram crescendo. Então fazer um-a-um e N-a-N. Recomendações 1-para-1, 1-para-N, N-para-1 e N-para-N.\n",
    "\n",
    "Estou pensando em uma métrica que trate de forma acumulada, p.e.:\n",
    "\n",
    "- **A) 1-para-1:** Para cada uma empresa dentro de cada portfólio, eu vejo se a recomendação já está dentro do portfólio.\n",
    "\n",
    "- **B) 1-para-N:** Para cada uma empresa dentro de cada portfólio, requisito N recomendações. Verifico quantas das N recomendações está no portfólio.\n",
    "\n",
    "- **C) N-para-1:** Amostro N empresas e requisito 1 recomendação e confiro se está dentro do portfólio. Repito isso uma M vezes.\n",
    "\n",
    "- **D) N-para-N:** Amostro N empresas e requisito N recomendação e confiro se está dentro do portfólio. Repito isso uma M vezes. \n",
    "\n",
    "4.1) E o desempate? Pensando...\n",
    "\n",
    "Ideia: um misto entre o ranqueamento individual (1-para-N), mais votados e sorteio aleatório dos empatados por último.\n",
    "\n",
    "Como abordar isso?\n",
    "\n",
    "Posso fazer algo iterativo, tendo como objetivo obeter as $k$ recomendações solicitadas. Como o cálculo dos vizinhos é feito só uma vez, processamento não será um problema.\n",
    "\n",
    "- **a)** Pego $L \\times \\text{div}(k,N_{in}) + \\min(\\text{mod}(k,N_{in}),1)$ recomendações por usuário de entrada.\n",
    "- **b)** Ordeno por votação e desempato por ordem de proximidade individual.\n",
    "- **c)** Se a lista ficar curta, faço $L \\leftarrow L+1$ e volto para **a** até cehgar a $k$ recomendações.\n",
    "\n",
    "\n",
    "\n",
    "*Author: Israel Oliveira [\\[e-mail\\]](mailto:'Israel%20Oliveira%20'<prof.israel@gmail.com>)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType, List\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import SVD, accuracy, Dataset, Reader\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-22T02:10:13+00:00\n",
      "\n",
      "CPython 3.7.7\n",
      "IPython 7.15.0\n",
      "\n",
      "compiler   : GCC 8.3.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-7626-generic\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "loguru 0.5.1\n",
      "scipy 1.5.0\n",
      "surprise 0.1\n",
      "numpy  1.19.0\n",
      "pandas 1.0.5\n",
      "\n",
      "Git hash: 1b3648710901d000d99c99652b7708a74d60ed4c\n",
      "Git repo: https://github.com/ysraell/aceleradev_private.git\n",
      "Git branch: master\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before close.\n",
    "%watermark\n",
    "%watermark -p loguru\n",
    "%watermark -p scipy\n",
    "%watermark -p surprise\n",
    "%watermark --iversion\n",
    "%watermark -b -r -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/'\n",
    "top_cols = pd.read_csv('top_cols.csv')['cols'].to_list()\n",
    "df_marked = pd.read_csv(path_data+'estaticos_market.csv', usecols=top_cols)\n",
    "col_user = 'id'\n",
    "top_cols.remove(col_user)\n",
    "\n",
    "rest_cols = []\n",
    "for col in top_cols:\n",
    "    df_marked[col] = df_marked[col].fillna(0)*1\n",
    "\n",
    "def normalize(x):\n",
    "    return (x-np.min(x))/(np.max(x) - np.min(x)) if (np.max(x) - np.min(x)) > 0 else (x-np.min(x))\n",
    "\n",
    "escala = 100\n",
    "for col in top_cols:\n",
    "    df_marked[col] = (escala*normalize(df_marked[col].tolist())).astype(np.uint8)\n",
    "    \n",
    "remove_cols = []\n",
    "for col in top_cols:\n",
    "    if df_marked[col].nunique() == 1:\n",
    "        remove_cols.append(col)\n",
    "\n",
    "df_marked = df_marked.drop(columns=remove_cols)\n",
    "for col in remove_cols:\n",
    "    top_cols.remove(col)\n",
    "\n",
    "df_marked = pd.melt(df_marked, id_vars=[\"id\"], var_name=\"itemID\", value_name=\"rating\").rename(columns={\"id\": \"userID\"})\n",
    "\n",
    "reader = Reader(rating_scale=(0, escala))\n",
    "#data = Dataset.load_from_df(df_marked[['userID', 'itemID', 'rating']].sample(frac=0.2), reader)\n",
    "data = Dataset.load_from_df(df_marked[['userID', 'itemID', 'rating']], reader)\n",
    "del df_marked\n",
    "\n",
    "df_ep_list = [pd.read_csv(path_data+'estaticos_portfolio{}.csv'.format(i+1)) for i in range(3)]\n",
    "tmp = []\n",
    "for i in range(3):\n",
    "    df_ep_list[i]['P'] = i+1 \n",
    "    tmp.append(df_ep_list[i][['id','P']])\n",
    "df_ep = pd.concat(tmp)\n",
    "del df_ep_list\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uid = NewType('uid', int)\n",
    "Raw = NewType('raw', str)\n",
    "\n",
    "def flat(a):\n",
    "    return functools.reduce(operator.iconcat, a, [])\n",
    "\n",
    "class ExSVD(SVD):\n",
    "    \"\"\"\n",
    "        Classe extendida da surprise.SVD.\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,**args):\n",
    "        self.matrix_dict = {}\n",
    "        super().__init__(**args)\n",
    "\n",
    "    def fit(self,trainset: Dataset):\n",
    "        \"\"\"\n",
    "            Reimplementei a SVD.fit para colocar um logger nível INFO.\n",
    "        \"\"\"\n",
    "        logger.info(\"Treinando modelo SVD...\")\n",
    "        super().fit(trainset)\n",
    "        logger.info(\"Pronto!\")\n",
    "    \n",
    "    def _get_neighbors(self,uid: Uid, k: int = 1, black_list: List[Uid] = []):\n",
    "        \"\"\"\n",
    "            Calcula todas as distâncias entre 'uid' de entrada e todos os outros 'uid'.\n",
    "            A distância calciulada é armazenda e não calculada novamente. \n",
    "        \"\"\"\n",
    "        black_list.append(uid)\n",
    "        k = k if k >= 0 else 0\n",
    "        logger.info(\"Calculando todos os vizinhos...\")\n",
    "        for uid2 in tqdm(self.trainset.all_users()):\n",
    "            ordered = tuple(sorted((uid,uid2)))\n",
    "            if (uid2 not in black_list) and (ordered not in self.matrix_dict.keys()):\n",
    "                self.matrix_dict[ordered] = cosine(self.pu[uid],self.pu[uid2])\n",
    "        return [x[0] for x in sorted(\n",
    "            [\n",
    "                (uid2, self.matrix_dict[tuple(sorted((uid,uid2)))]) \n",
    "                for uid2 in self.trainset.all_users()\n",
    "                if (uid2 not in black_list)\n",
    "            ], key=lambda x: x[1])][:k-1]\n",
    "\n",
    "    def _uid2raw(self, uid: Uid)-> str:\n",
    "        '''\n",
    "            uid -> raw.\n",
    "            Valor interno para externo, o nome original do usuário.\n",
    "        '''\n",
    "        return self.trainset.to_raw_uid(uid)\n",
    "    \n",
    "    def _raw2uid(self, raw: Raw)-> int:\n",
    "        '''\n",
    "            raw -> uid.\n",
    "            Valor externo para interno, o id interno do usuários..\n",
    "        '''\n",
    "        return self.trainset.to_inner_uid(raw)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-22 03:09:04.401 | INFO     | __main__:fit:19 - Treinando modelo SVD...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-22 03:11:41.276 | INFO     | __main__:fit:21 - Pronto!\n"
     ]
    }
   ],
   "source": [
    "ex_algo = ExSVD(n_factors=5, verbose=True)\n",
    "ex_algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-22 03:17:04.062 | INFO     | __main__:_get_neighbors:30 - Calculando todos os vizinhos...\n",
      "100%|██████████| 462298/462298 [00:00<00:00, 654952.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[75, 74, 67, 41, 24, 37, 363, 88, 89]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_algo._get_neighbors(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomender(self, in_list: List[Raw], k: int = 1, L: int = 3, limit: int = 10)-> List[Raw]:\n",
    "    '''\n",
    "        Faz as recomendacoes.\n",
    "        ##### Função incompleta #####\n",
    "    '''\n",
    "    # Pega quantas recomendações por usuário em `in_list`,\n",
    "    # mas sem deixar faltar\n",
    "    N_in = len(in_list)\n",
    "    k = k if k > 0 else 1\n",
    "    R_per_in = L*(k//N_in + min(k%N_in,1))\n",
    "    \n",
    "    uid_in_list = []\n",
    "    for raw in in_list:\n",
    "        uid_in_list.append(self._raw2uid(raw))\n",
    "\n",
    "    done = False\n",
    "    flag = True\n",
    "    Rounds = 0\n",
    "    while limit and (not done):\n",
    "        Rounds += 1\n",
    "        # Ele sempre pega todos novamente.\n",
    "        recomendations_list = []\n",
    "        for i,uid in enumerate(uid_in_list):\n",
    "            logger.info(\"Calculando todos os vizinhos...{:,}/{:,} (Round: {:,}).\".format(i+1,N_in,Rounds))\n",
    "            recomendations_list.append(self._get_neighbors(uid,R_per_in,in_list))\n",
    "        # Quando limit = 0, encerra.\n",
    "        limit -= 1\n",
    "        # Quando tem gente o suficiente, encerra.\n",
    "        if len(set(flat(recomendations_list))) >= k:\n",
    "            done = True\n",
    "        # Depois do primeiro loop, pega um a mais.\n",
    "        R_per_in += 1\n",
    "    \n",
    "    # Agora eu preciso rodar isso para ver como posso seguir.\n",
    "    return recomendations_list\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-22 03:25:51.084 | INFO     | __main__:recomender:23 - Calculando todos os vizinhos...1/2 (Round: 1).\n",
      "2020-06-22 03:25:51.085 | INFO     | __main__:_get_neighbors:30 - Calculando todos os vizinhos...\n",
      "100%|██████████| 462298/462298 [00:00<00:00, 645036.69it/s]\n",
      "2020-06-22 03:25:52.710 | INFO     | __main__:recomender:23 - Calculando todos os vizinhos...2/2 (Round: 1).\n",
      "2020-06-22 03:25:52.710 | INFO     | __main__:_get_neighbors:30 - Calculando todos os vizinhos...\n",
      "100%|██████████| 462298/462298 [00:00<00:00, 632462.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[148, 367], [339312, 610]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomender(ex_algo,df_ep['id'].head(2).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
