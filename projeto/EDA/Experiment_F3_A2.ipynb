{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment F\n",
    "\n",
    "2) Implementar um framework de busca de hiperparâmetros.\n",
    "\n",
    "2.1) Parâmetros específicos para cada método de processamento do ds.\n",
    "\n",
    "2.2) N top colunas (`top_cols`) do dataset.\n",
    "\n",
    "2.3) Parâmetro $L$ (`recomender(...,L,...)`).\n",
    "\n",
    "5) Implementar como entrada uma empresa nova, conter mapeamento de valores.\n",
    "\n",
    "Talvez criar o notebook da Second_View, com:\n",
    "1) Verificar `sklearn.inspection.permutation_importance`.\n",
    "\n",
    "- Author: Israel Oliveira [\\[e-mail\\]](mailto:'Israel%20Oliveira%20'<prof.israel@gmail.com>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType, List\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import FactorAnalysis, FastICA, PCA, IncrementalPCA, NMF, TruncatedSVD\n",
    "from collections import defaultdict, Counter\n",
    "import functools\n",
    "import operator\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  1.19.0\n",
      "pandas 1.0.5\n",
      "2020-07-27 \n",
      "\n",
      "CPython 3.7.8\n",
      "IPython 7.16.1\n",
      "\n",
      "compiler   : GCC 8.3.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-7634-generic\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 90851ad626ecf179ca5598e03ce4034e1a78e1a7\n",
      "Git repo   : https://github.com/ysraell/aceleradev_private.git\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before close.\n",
    "%watermark -d --iversion -b -r -g -m -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Manhattan(X,vec):\n",
    "    return abs(X - vec).sum(-1)\n",
    "\n",
    "def Camberra(X,vec):\n",
    "    return abs((X - vec)/(X + vec)).sum(-1)\n",
    "\n",
    "def BrayCurtis(X,vec):\n",
    "    return abs((X - vec)).sum(-1) / abs((X - vec)).sum(-1).sum(-1)\n",
    "\n",
    "def np_cossine(X,vec):\n",
    "    return np.array([sum(X[i]*vec) / sum(X[i]**2)*sum(vec**2) for i in range(X.shape[0])])\n",
    "\n",
    "def npj_cossine(X,vec):\n",
    "    return npj.array([sum(X[i]*vec) / sum(X[i]**2)*sum(vec**2) for i in range(X.shape[0])])\n",
    "\n",
    "def scy_cossine(X,vec):\n",
    "    return np.array([cosine(X[i],vec) for i in range(X.shape[0])])\n",
    "\n",
    "dist_func = [Manhattan, Camberra, BrayCurtis, np_cossine, scy_cossine]\n",
    "\n",
    "def Nothing(arg):\n",
    "    return arg\n",
    "\n",
    "def npSVD(M):\n",
    "    u, _, _ = np.linalg.svd(M, full_matrices=False)\n",
    "    return u\n",
    "\n",
    "def _PCA(M,n_components=None):\n",
    "    out = PCA(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _FastICA(M,n_components=None):\n",
    "    out = FastICA(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _FactorAnalysis(M,n_components=None):\n",
    "    out = FactorAnalysis(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _IncrementalPCA(M,n_components=None):\n",
    "    out = IncrementalPCA(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _TruncatedSVD(M,n_components=None):\n",
    "    out = TruncatedSVD(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "def _NMF(M,n_components=None):\n",
    "    out = NMF(n_components=n_components)\n",
    "    return out.fit_transform(M)\n",
    "\n",
    "redux_func = [Nothing, npSVD, _NMF, _TruncatedSVD, _IncrementalPCA, _FactorAnalysis, _FastICA, _PCA]\n",
    "\n",
    "def escalaropt_missings(df: pd.DataFrame, score: dict):\n",
    "    df_score = pd.DataFrame(score.items(), columns=['col','score'])\n",
    "    df_score['escala_opt'] = 1-normalize((np.sqrt(df_score.score)))\n",
    "    df_score['escala_opt'] = df_score['escala_opt'].apply(lambda x: max(x,0.1))\n",
    "    for _,row in df_score.iterrows():\n",
    "        df[row.col] = row.escala_opt*df[row.col]\n",
    "    return df\n",
    "\n",
    "def escalaropt_std(df: pd.DataFrame, score: dict):\n",
    "    df_score = pd.DataFrame(score.items(), columns=['col','score'])\n",
    "    df_score['escala_opt'] = normalize([np.sqrt(np.sqrt(np.sqrt(df[col].std()))) for col in df_score['col']])\n",
    "    df_score['escala_opt'] = df_score['escala_opt'].apply(lambda x: max(x,0.1))\n",
    "    for _,row in df_score.iterrows():\n",
    "        df[row.col] = row.escala_opt*df[row.col]\n",
    "    return df\n",
    "\n",
    "def escalaropt_entropy(df: pd.DataFrame, score: dict):\n",
    "    df_score = pd.DataFrame(score.items(), columns=['col','score'])\n",
    "    df_score['escala_opt'] = normalize([(-sum((df[col]+1)*np.log(df[col]+1))) for col in df_score['col']])\n",
    "    df_score['escala_opt'] = df_score['escala_opt'].apply(lambda x: max(x,0.1))\n",
    "    for _,row in df_score.iterrows():\n",
    "        df[row.col] = row.escala_opt*df[row.col]\n",
    "    return df\n",
    "\n",
    "def scalarop_nothing(arg, arg2):\n",
    "    return arg\n",
    "\n",
    "procDS_func = [scalarop_nothing, escalaropt_missings, escalaropt_std, escalaropt_entropy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage.ipynb  data  src\n"
     ]
    }
   ],
   "source": [
    "!ls ../app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../app/src/')\n",
    "from train import *\n",
    "from recommender import Recommender \n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 02:41:48.831 | INFO     | utils:load_dataset:82 - Carregando dataset de treino...\n",
      "2020-07-27 02:41:59.387 | INFO     | utils:load_dataset:91 - ...pronto!\n",
      "2020-07-27 02:41:59.387 | INFO     | utils:load_dataset:95 - Carregando dataset de teste...\n",
      "2020-07-27 02:41:59.397 | INFO     | utils:load_dataset:104 - ...pronto!\n",
      "2020-07-27 02:41:59.417 | INFO     | utils:feat_proc:128 - Processando as features...\n",
      "2020-07-27 02:42:36.189 | INFO     | utils:feat_proc:163 - ...pronto!\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = load_dataset(path_data = '../app/data/', test_list = [0, 1], train_test_merged = False)\n",
    "ds, score = feat_proc(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search(N=1, process_values = Nothing, factorize = Nothing, vector_distance_list = [Manhattan]):\n",
    "    ex_algo = ExMatrix(process_values = process_values, factorize = factorize)\n",
    "    ex_algo.fit(ds, score)\n",
    "    out = {}\n",
    "    for dist in vector_distance_list:\n",
    "        ex_algo.vector_distance = dist\n",
    "        print(dist.__name__)\n",
    "        tmp ={1: [], 2: []}\n",
    "        t = time()\n",
    "        for row in tqdm(df_test.iterrows()):\n",
    "            recs = ex_algo.recomender([row[1].id],k=N)\n",
    "            tmp[row[1].P].append(any([x in df_test.loc[df_test.P == row[1].P].id.to_list() for x in recs])*1)\n",
    "        t = time()-t\n",
    "        out[dist.__name__] = {i: (sum(val)/max(1,len(val)), sum(val), len(val)) for i,val in tmp.items()}\n",
    "        out[dist.__name__]['t'] = t\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = dist_func #[Manhattan, scy_cossine, Camberra, BrayCurtis, np_cossine] #[Manhattan, Camberra, BrayCurtis] #dist_func\n",
    "proc_list = [escalaropt_std, escalaropt_entropy] #procDS_func #[Nothing] #procDS_func\n",
    "redux_list =  redux_func #redux_func #[Nothing] #[Nothing, npSVD, _NMF, _PCA, _FactorAnalysis] #redux_func\n",
    "n_components_dict = {Nothing.__name__ : False,\n",
    "                  #_npSVDj.__name__: False,\n",
    "                  npSVD.__name__: False,\n",
    "                  _NMF.__name__ : True,\n",
    "                  _TruncatedSVD.__name__ : True,\n",
    "                  _IncrementalPCA.__name__ : True,\n",
    "                  _FactorAnalysis.__name__ : True,\n",
    "                  _FastICA.__name__ : True,\n",
    "                  _PCA.__name__ : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_csv_name = 'Results_A2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laoded = pd.read_csv(results_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results,df_e):\n",
    "    df = pd.DataFrame(results, columns=['pre_proc','redux_func','n_components','dist','t','P1pp','P1_True','P1_len','P2pp','P2_True','P2_len'])\n",
    "    out = pd.concat([df_e, df])\n",
    "    #df_laoded.df_laodedto_csv('Results_redux_prepro.csv',index=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 02:51:25.786 | INFO     | model:fit:69 - Processando valores.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done?: ['escalaropt_std', 'Nothing', 169].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 02:51:26.793 | INFO     | model:fit:73 - Fatorizando.\n",
      "2020-07-27 02:51:26.794 | INFO     | model:fit:78 - Matriz pronta.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831it [15:20,  1.11s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camberra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n",
      "769it [13:09,  1.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-e8698f13632f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_laoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdist_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mdist_list_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdist_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_laoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactorize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_distance_list\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdist_list_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mdf_laoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_laoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-9ecefed6691a>\u001b[0m in \u001b[0;36mSearch\u001b[0;34m(N, process_values, factorize, vector_distance_list)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_algo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecomender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/aceleradev_private/projeto/app/src/model.py\u001b[0m in \u001b[0;36mrecomender\u001b[0;34m(self, in_list, k, L, Fk, limit)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# Ele sempre pega todos novamente.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             recomendations_list = [\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_per_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muid_in_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muid_in_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             ]\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# Quando limit = 0, encerra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/aceleradev_private/projeto/app/src/model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# Ele sempre pega todos novamente.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             recomendations_list = [\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_per_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muid_in_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muid_in_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             ]\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# Quando limit = 0, encerra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/aceleradev_private/projeto/app/src/model.py\u001b[0m in \u001b[0;36m_get_neighbors\u001b[0;34m(self, uid, k, black_list)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         out = [\n\u001b[1;32m     92\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-ba5620f8e9a9>\u001b[0m in \u001b[0;36mCamberra\u001b[0;34m(X, vec)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCamberra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mBrayCurtis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_components_list = [n for n in range(10,160,10)]\n",
    "n=0\n",
    "for redux in redux_list:\n",
    "    for proc in proc_list:\n",
    "        if n_components_dict[redux.__name__]:\n",
    "            for n_components in n_components_list:\n",
    "                cond = (df_laoded['pre_proc'] == proc.__name__) & (df_laoded['redux_func'] == redux.__name__) & (df_laoded['n_components'] == n_components)\n",
    "                print(\"Done?: {}.\".format([proc.__name__, redux.__name__, n_components]))\n",
    "                if (sum(cond) == 0) or (not all([d.__name__ in df_laoded.dist.loc[cond].unique() for d in dist_list])):\n",
    "                    dist_list_tmp = [d for d in dist_list if d.__name__ not in df_laoded.dist.loc[cond].unique()]\n",
    "                    def redux_tmp(M):\n",
    "                        return redux(M,n_components=n_components)\n",
    "                    tmp = Search(process_values = proc, factorize = redux_tmp, vector_distance_list = dist_list_tmp)\n",
    "                    results = [[proc.__name__, redux.__name__, n_components] + r for r in [[key]+[tmp[key]['t']]+flat([list(tmp[key][i+1]) for i in range(2)]) for key in tmp.keys()]]\n",
    "                    df_laoded = save_results(results,df_laoded)\n",
    "                    df_laoded.to_csv(results_csv_name,index=False)\n",
    "                else:\n",
    "                    print(\"Done: {}.\".format([proc.__name__, redux.__name__, n_components]))\n",
    "        else:\n",
    "            n_components = ds.shape[1]\n",
    "            cond = (df_laoded['pre_proc'] == proc.__name__) & (df_laoded['redux_func'] == redux.__name__) & (df_laoded['n_components'] == n_components)\n",
    "            print(\"Done?: {}.\".format([proc.__name__, redux.__name__, n_components]))\n",
    "            if (sum(cond) == 0) or (not all([d.__name__ in df_laoded.dist.loc[cond].unique() for d in dist_list])):\n",
    "                dist_list_tmp = [d for d in dist_list if d.__name__ not in df_laoded.dist.loc[cond].unique()]\n",
    "                tmp = Search(process_values = proc, factorize = redux, vector_distance_list= dist_list_tmp)\n",
    "                results = [[proc.__name__, redux.__name__, n_components] + r for r in [[key]+[tmp[key]['t']]+flat([list(tmp[key][i+1]) for i in range(2)]) for key in tmp.keys()]]\n",
    "                df_laoded = save_results(results,df_laoded)\n",
    "                df_laoded.to_csv(results_csv_name,index=False)\n",
    "            else:\n",
    "                print(\"Done: {}.\".format([proc.__name__, redux.__name__, n_components]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(columns=['pre_proc','redux_func','n_components','dist','t','P1pp','P1_True','P1_len','P2pp','P2_True','P2_len'])\n",
    "#df.to_csv(results_csv_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
